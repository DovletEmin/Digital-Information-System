version: '3.8'

services:
  redis:
    image: redis:7-alpine
    ports:
      - "6379:6379"
    restart: unless-stopped

  celery-worker:
    build:
      context: .
      dockerfile: Dockerfile
    command: >
      celery -A src worker --loglevel=info
    working_dir: /app/src
    volumes:
      - ./:/app:rw
    env_file:
      - .env
    environment:
      CELERY_BROKER_URL: "redis://redis:6379/0"
      ELASTICSEARCH_URL: "http://elasticsearch:9200"
      PYTHONUNBUFFERED: "1"
      DJANGO_SETTINGS_MODULE: src.settings
    depends_on:
      - redis
      - elasticsearch
    restart: unless-stopped

  celery-beat:
    build:
      context: .
      dockerfile: Dockerfile
    command: >
      celery -A src beat --loglevel=info --scheduler django_celery_beat.schedulers:DatabaseScheduler
    working_dir: /app/src
    volumes:
      - ./:/app:rw
    env_file:
      - .env
    environment:
      CELERY_BROKER_URL: "redis://redis:6379/0"
      ELASTICSEARCH_URL: "http://elasticsearch:9200"
      PYTHONUNBUFFERED: "1"
      DJANGO_SETTINGS_MODULE: src.settings
    depends_on:
      - redis
      - elasticsearch
    restart: unless-stopped

  elasticsearch:
    image: elasticsearch:7.17.13
    environment:
      discovery.type: single-node
      ES_JAVA_OPTS: "-Xms512m -Xmx512m"
    ports:
      - "9200:9200"
    volumes:
      - esdata:/usr/share/elasticsearch/data
    ulimits:
      memlock:
        soft: -1
        hard: -1
    healthcheck:
      test: ["CMD-SHELL", "curl -sS http://localhost:9200/ >/dev/null || exit 1"]
      interval: 10s
      timeout: 10s
      retries: 5
    restart: unless-stopped

volumes:
  esdata: